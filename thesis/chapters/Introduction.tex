\chapter{Motivation}
\label{ch:Motivation}

Humans when perceiving new information tend to form impressions (mental representation) of the attributes of objects. Impressions that are similar in attributes tend to cohere into categories \cite{fiske1998stereotyping}\cite{allport1954nature}. This is due to the innate tendency of the human mind to categorize the world to simplify, store perceived information in mental representation and activate the stored information automatically and unconsciously when one encounters
a category member \cite{ComputationalEthics}. The same mechanism when applied to perceive complex social structures leads to social categorization(constructs) and stereotypes. Social categorization could be based on gender, race, age, sexual orientation etc. and having over-generalized beliefs about these social categories leads to social stereotypes \cite{beukeboom2019stereotypes}\cite{ComputationalEthics}.	
\\

Social stereotypes are firmly implanted and reinforced by cognitive processes and can have
an automatic and unrecognized biased effect on behaviours and judgements [Kaufman, 2018]
for example, Racial bias in resume (job applicants with African American sounding names
got fewer callbacks [Tsvetkov, 2020]), gender bias in recruitment ([Moss-Racusin et al., 2012])
among several others. Stereotypes can be positive or negative (sentiment). When either positive or negative stereotypes are generalized, they will have negative effect. For example, stereotypes such as “Asians are good at math” though having positive sentiment, when generalized, can have negative affect on Asians who are not good at math. This is referred as stereotypical threat. Stereotypical threat can be defined as situation in which an individual is judged by the stereotypes (negative or positive) of their social group. This often leads to anxiety, negative feelings and impacts performance \cite{beukeboom2019stereotypes}\cite{spencer2016stereotype}. Social
bias can thus be described as the affective component of social stereotypes which leads to unequal treatment or
discrimination.
\\

 Language use and communication play a crucial role in the maintenance and transmission of stereotypes. Language in subtle ways constructs and maintains beliefs about social categories through linguistics \cite{beukeboom2019stereotypes}.  The linguistic biases and the variation in language when describing social stereotypes are the ways through which the stereotypes are reflected. \cite{burgers2020language}. These variations or biases in language can be expressed overtly or in a more subtle way in interpersonal communication among social groups and the stereotypes becomes shared knowledge (similar beliefs and expectancies about social categories). In order to gain important insights about the stereotypes and their manifestation as shared knowledge among social groups, it is crucial to focus on language use in communication about socially categorized people \cite{beukeboom2019stereotypes}.
 
 
%  Studying the natural language through which stereotypes are manifested  can lead to gaining important insights about the social-category stereotypes shared within the cultural groups \cite{beukeboom2019stereotypes}.
 
 
 
 
%  can be overtly expressed consciously (explicit) or unconsciously (implicit) in interpersonal communication (either online or in real life) among social groups \cite{hovland1948social}.   Hence, by studying the natural language in which various biases may occur in combination, important insights can be gained about the social-category stereotypes shared within the cultural groups. 
 \pagebreak
%  This linguistically biased textual data when used for applications (natural language processing tasks) leads to further propagation of the stereotypes.
%  Language reflects the targeted social groups for stereotyping and is the main carrier of the stereotypic information associated with the target groups  \cite{beukeboom2019stereotypes}.
%  The social categories and stereotype communication (SCSC) framework describes two broad groups of linguistic biases which contribute to stereotype formation and maintenance. The first group relates to generic linguistic labels used to categorize social groups. The second group of biases relates to the linguistic variation in the language use when describing behaviour that is either consistent or inconsistent with the existing social stereotypes \cite{burgers2020language}

As stereotyping cannot be avoided at-least at the level of cognition; the linguistic assessment of the social stereotypes present in the language use plays an important role to further avoid maintenance and transmission to natural language processing applications. 

% textual data used for natural language processing through classifying different types of biases present in the text sequences,

% With the onset of internet by which people across different countries with different social backgrounds share and communicate their social beliefs verbally, the need to assess the social stereotypes present in the data(text) plays an important role to further avoid maintenance and transmission of stereotypes. 

% The computational analysis and synthesis of natural language argumentation is called computational argumentation. Argument search \cite{wachsmuth2017building}, fact-checking \cite{samadi2016claimeval}, writing support\cite{stab2017argumentative},  automated decision assistance \cite{rinott2015show} are few of the applications of computational argumentation. Computational argumentation relies on computational linguistics for understanding language which is accomplished through statistical machine learning and deep learning approaches.
% Argumentation is a social activity and prone to social bias. Computational argumentation and its applications rely on web arguments which are provided by debate portals. These portals have been shown to be socially biased \cite{spliethover2020argument}. Hence with this insight, further research on affects of social bias in different stages of CA can be further examined. 
% In this thesis,impact of social bias in an argument is studied. Its implications, related work, assessment of social bias in an argumentative unit(premise and conclusion ) are researched.


% \\
% \\

% \textbf{Focus on the context of the thesis} 
% \begin{enumerate}
%     \item What is bias in NLP?\\ 
%     \textbf{Social Science Domain} - "Judgement based on preconceived notions or prejudices". \cite{campolo2017ai} \\
% 	\textbf{ML/ Statistics Domain} - "Inability to capture true relationship between dependent and independent variables." \cite{campolo2017ai}
% 	\item Categories of bias as stated by Crawford can be broadly classified into two types namely 
% 	\begin{itemize}
% 	    \item Representational bias: "Representation bias happens from the way we define and sample from a population."\cite{suresh2019framework}
%         Systems that represent embedded bias. Here the focus is more on the representational social bias.The types of social bias focused in this paper are Gender bias and Racial bias. 
% 	    \item Allocation bias : Consequences of representational bias leading to bias in high stake decision making such as loan application, dating, hiring etc. 
% 	\end{itemize}
	
	
%     \item Present situation ??
%     \begin{itemize}
%         \item Bias found in many core technologies as well as the application of NLP. 
%     \end{itemize}
% % `   \item Consequences of detecting bias 
% %     \begin{itemize}
% %         \item "Analyze sentiments by transferring user biases to textual features."\cite{calais2011bias}
% %     \end{itemize}
% \end{enumerate}

% One expresses his thoughts by taking a stance on the topic and justifies it by providing reasons. The composition of a claim(the statement that conveys stance towards topic) supported by reasons(premises) \cite{walton2005fundamentals} is termed as an argument. The process of using arguments aimed to justify, persuade, agree upon a topic is called argumentation. The need for argumentation arises when a claim is subject to doubt or controversy. A claim becomes questionable when different people with different interests, cultural socialization share social beliefs and attitudes through interpersonal communication.

\subsection{problem statement}
There has been a staggering increase in the amount of digital data in the last decade. According to the international data corporation (IDC) the digital data is expected to grow from 33 to 175 Zeta Bytes by 2025 \cite{IDC}. This explosion of data is due to the social networks, online commerce/services and servers filled with archives \cite{IDC}. Machine learning systems which have penetrated daily walks of life from movie recommendations systems to high-stakes decision making essentially need this data to build powerful systems. Machine learning algorithm starts learning using the data (training examples) to solve learning problem (classification etc) \cite{jordan2015machine}. For building robust machine learning systems that generalize well across domains, hundred to thousand training examples are required \cite{radford2019language}. Hence, Organizations when developing powerful machine learning systems have on occasion flouted the rules of acceptable practices and even the law to acquire more data \cite{lloyd2018bias}. The large volumes of data acquired from heterogeneous sources could be incomplete, biased or skewed (under or over-representing population in sampling)\cite{campolo2017ai}. If the data upon which the algorithms are trained is biased then the algorithm will implicitly learn that behavior as normal\cite{lloyd2018bias}. Stereotypes are sustained and maintained by this biased data. This ultimately leads to biased models or learning algorithms whose outcomes(decisions) are based on undue prejudices or favoritism towards different social or racial groups \cite{mehrabi2019survey}. 
%It has been shown that algorithms (active/online-learning, interactive systems) can also amplify bias in data due to feedback loop between biased algorithm and user \cite{zhao2017men} \cite{mehrabi2019survey}.
\\
Natural Language Processing tasks and applications such as machine translation, sentiment analysis, hate-speech detection, text generation \cite{blodgett2020language} have been shown to be affected by this stereotypical bias. Use of these models in critical and high-stake decision-making applications like criminal justice, healthcare, employment matching will have a direct impact on lives and can harm society \cite{mehrabi2019survey}.
\\
% Machine learning models trained for natural language processing have been identified for capturing social biases \cite{mehrabi2019survey}.This finding had led to a spike in the amount of research work done in analysing "bias".  \cite{blodgett2020language}.
With this awareness and harms caused by the bias in data, there has been a spike in the amount of research work done in analysing bias.
Broadly, bias detection or mitigation techniques fall under three categories \cite{mehrabi2019survey}.
\begin{itemize}
    \item \textbf{Pre-processing:} Pre-processing techniques try to analyze and transform the data or its representation (vector representation – Representation of text as vector of numbers for the machine learning algorithm to process) to identify or remove bias.
    \item \textbf{In-processing.} In-processing techniques try to change or modify the state-of-the-art learning algorithm.
    \item  \textbf{Post-processing.} Post processing techniques are applied on the trained model to mitigate bias in the model.
\end{itemize}   
% \pagebreak
% wherein pre-trained language models trained on the huge corpus (Wikipedia, book corpus, openWebText etc) are used and fine-tuned to detect the presence of stereotypical social bias in data (text-sequences).
This thesis focuses on the pre-processing technique using language models, i.e to analyze stereotypical social biases present in textual data using pre-trained language models. Language modelling is
a task of assigning probabilities to sequence of words and a system which does this task is termed as language model\cite{DNLP}. It has been shown that, language
models when trained on textual data using neural architectures which handle sequential data tend to not only capture the complex hierarchical structures and long term dependencies 
but also the biases reflected by the data. Hence,
language models when trained in an unsupervised way on massive amounts of user generated real world textual data tend to capture the stereotypes along with the complex grammatical structures present in the data as well \cite{nadeem2020stereoset}\cite{ruder2019neural}\cite{brown2020language}. This knowledge of complex grammatical structures and stereotypical knowledge gained through training could be transferred and used for assessing the stereotypes embedded in the textual data which is the main goal. In the thesis, this transfer learning technique is used wherein pre-trained language models trained on vast textual data are fine-tuned to classify different types of social biases present in the text sequences. Transfer learning technique of transferring
the general domain knowledge gained through pre-training and fine-tuning to target domain task of classification is useful when dealing with NLP problems where a mass of data and computational resources are unavailable \cite{transfer_Learning} that is the case here as finding and validating stereotypes(subjective in nature) is difficult. As part of thesis, experiments are performed using different pre-trained language models (with respect to different training corpora, stereotypical biases present in the language model etc) to classify different types of biases.
\\

In this thesis, the following research questions are asked:
\begin{enumerate}
    \item How will the different pre-trained language models (with respect to different training corpora, stereotypical biases etc) affect the detection of social bias?
    \item How far transfer learning (applying the real-world knowledge gained through language modelling) is useful when detecting stereotypical social biases?
\end{enumerate}

\subsection{Thesis structure}
\begin{enumerate}
    \item Introduction
        \begin{enumerate}
            \item Motivation
            \item Problem statement
            \item Structure and contributions of thesis
        \end{enumerate}
    \item Background
        \begin{enumerate}
        \item Language, social identity and stereotyping
        \item Technical background
        \begin{itemize}
            \item Introduction to Machine learning and Deep learning 
                \begin{enumerate}
                    \item Machine learning pipeline
                    \item Neural Networks architecture
                    \item Recurrent Neural Networks
                    \item Transformer architecture
                \end{enumerate}
            \item Natural language processing and vector representation
                \begin{enumerate}
                    \item Vector representation of language 
                    \item Static word embedding
                    \item Contextual word embedding
                \end{enumerate}
            \item Language models
                \begin{enumerate}
                    \item Language modeling
                    \item Transfer learning
                    \item BERT architecture
                \end{enumerate}
        \end{itemize}
            \item Bias and bias detection techniques in natural language processing
        \end{enumerate}
    \item Approach 
        \begin{itemize}
        \item Overview of the approach
        \item Description of pre-trained language models and baselines
        \item Experimental setup
        \end{itemize} 
    \item Data 
        \begin{enumerate}
            \item Data statistics 
            \item Data preparation 
        \end{enumerate}
% \pagebreak
    \item Experiments 
        \begin{itemize}
        \item Detection of social bias
            \begin{itemize}
                \item Features based Machine learning approach.
                \begin{itemize}
                    \item Feature set
                    \item Experiments with Machine learning classifier models
                    % \begin{itemize}
                    %     \item Logistic regression 
                    %     \item Support vector machine 
                    %     \item Random forests
                    % \end{itemize}
                \end{itemize}
                \item Deep learning based approach. 
                 \begin{itemize}
                    \item Pre-trained language models
                    \item Experiments using pre-trained language models
                \end{itemize}
            \end{itemize}
        \end{itemize}
    \item Evaluation and discussion 
    % \item Limitations (Optional)
        \begin{itemize}
            \item Discussion on the results and evaluation using Explainable AI approach
        \end{itemize}
    % \item Adaption to argument search (\textbf{Not sure})
    \item Conclusion
\end{enumerate}