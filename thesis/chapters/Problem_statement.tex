\chapter{Problem statement}
\label{Problem statement}


% Transfer
% of general domain knowledge gained through pre-training and fine-tuning to target domain task of classification is useful when dealing with NLP problems
% where a mass of data and computational resources are unavailable [Howard and Ruder, 2018] that is the case here as finding and validating stereo and anti-stereotypical(subjective in nature) is difficult.
% trained
% on the huge corpus (Wikipedia, book corpus, openWebText etc) are used and fine-tuned to detect
% the presence of stereotypical social bias in data (text-sequences)
\\
\\

% "The delivery of arguments for a given issue seen as one of the main applications of computational argumentation"\cite{wachsmuth2017building}\cite{rinott2015show}. Argument search is a technology which essentially fosters to query and search for supporting and opposing arguments on controversial topics. \cite{wachsmuth2017building} introduces a prototype (args.me) and framework for argument search engine which relies on standard indexing and retrieval of arguments. The retrieval process consists of retrieving, ranking and presentation of arguments when a user queries for a controversial issue. Social bias can be thus used as one of the quality factor to rank the arguments. 
% Social bias in language can manifest intentionally(explicit, overt) eg. "girls are not good in math" or unintentionally(implicit, subtle) eg. "We shouldnâ€™t lower our standards just to hire more women". 
% Sentence-level analysis of social bias can be more challenging as social bias can manifest intentionally or unintentionally.

% Though a majority of the research is being done in detecting and mitigating social biases in machine learning and natural language processing models, "detecting social bias in the direction of computational argumentation didn't receive much attention"\cite{spliethover2020argument}. The methodology used in the paper \cite{spliethover2020argument} relies on embedding model to assess social bias at the corpus level as a starting step.

% As these language models are trained on real world data ( openWebText, Wikipedia, book corpus etc), the stereotypical biases encoded in the real world are reflected in pre-trained language models such as BERT,XLNet,GPT-2 etc \cite{nadeem2020stereoset}\cite{nangia2020crows}. 