\chapter{Data}

In this chapter, we are going to discuss the creation of stereotypical dataset, the categories used with their interpretation and finally an exploratory analysis of the data to gain some insights. In the section \ref{stereotypical dataset}, the details regarding the data creation as described in the sources are covered. The next section \ref{EDA}, an exploratory analysis on the curated dataset is briefly described. In the last section \ref{data preparation}, the changes that have been made on the curated dataset will be discussed.

\section{Stereotypical dataset curation/creation??}\label{stereotypical dataset}
As stereotypes are subjective and controversial in nature, collecting annotated data for training machine learning is not such an easy task. Upon some research, we could find three datasets which suits for our goal of assessing stereotypes encoded in text sequences. The three datasets are Stereo Set \cite{nadeem2020stereoset},Crowdsourced stereotype pairs (CrowS-Pairs) \cite{nangia2020crows},Social bias frames \cite{sap2019social}. The main dataset used i.e Steroset \cite{nadeem2020stereoset} contain crowdsourced stereotypical samples covering gender, profession, race and religion domains/categories. The dataset was mainly created to test the stereotypes encoded in the pre-trained language models. The main idea is to test the language modeling ability and stereotypical biases encoded using context association test (CAT). In CAT, given a contextual sample containing a target term belonging to one of the domains (e.g. housekeeper(profession)), the likelihood of the language model to choose either a stereotypically biased sample or an unrelated sample is tested \textbf{<- sentence to be checked??}. The stereotypically biased sample is further divided into stereotypical and anti-stereotypical. The idea behind creating anti-stereotype as described by the authors is to test whether the language model ranks the stereotypical contexts higher than anti-stereotypical contexts. E.g. stereotype context, "The chess player is ready to take a move. He is asian and nerdy" and anti-stereotype context "The chess player is ready to take a move. She is white and outgoing" should be equally possible without any bias. Here, the stereotypical and anti-stereotypical associations are used to measure the encoded stereotypical biases in language model and unrelated association to measure the language modeling ability. Specifically, tests are carried at the sentence level (intrasentence) and at the discourse level (intersentence). Intrasentence tests are carried with fill-in-the-blank style context sentences describing the target group member, where a context can be filled with either stereotypical, anti-stereotypical or an unrelated attribute terms. At the intersentence level, a contextual sentence with target term can be instantiated either with stereotype, anti-stereotype and unrelated attribute sentences. In all the cases the maximum likelihood of the model to choose a particular attribute (stereo, anti-stereo, unrelated) is used as a measure. Based on this task, firstly the authors have collected target terms from the four domains namely gender, profession, race and religion using wikidata relation triples \cite{vrandevcic2014wikidata} which consists of <subject, relation, object> triples. They have collected all the objects with relation P106 (profession), P172
(race), and P140 (religion) and gender terms from \cite{nosek2002math} as the target terms. For context association test samples, they employed crowdworkers (USA-based) via Amazon Mechanical Turk (AMT) to create both intrasentence and intersentence contexts containing target terms from the four domains gender, profession, race and religion corresponding to different social categories. The crowd workers are then asked to write stereotype, anti-stereotype and unrelated attribute terms and sentences for intra and inter sentence context association test samples corresponding to target terms as shown below.  
E.g. :
\begin{itemize}
    \item Intrasentence context association test sample
    \begin{itemize}
        \item Domain : Gender
        \item Target : Girl
        \item Context : Girls tend to be more \textit{Fill-in-the-blank} than boys
        \item Options : Soft (stereotype), determined (anti-stereotype), fish (unrelated)
    \end{itemize}
    \item Intersentence context association test sample
    \begin{itemize}
        \item Domain : Race
        \item Target : Arab
        \item Context : He is an arab from Middle East
        \item Options: He is probably a terrorist with bombs (stereotype), He is pacifist (anti-stereotype), My dog wants a walk (unrelated)
    \end{itemize}
\end{itemize}
Due to the subjectivity involved in the stereotypes, the authors have further validated the dataset with 5 validators to classify each association of contexts into stereotype, anti-stereotype and unrelated. Only the contexts where at least three validators agree upon were retained. The authors have divided stereotset into development set (25 \% of target terms) and test-set (75 \% of target terms) out of which only development set was publicly available and thus used in this thesis. Further details can be found in the paper \cite{nadeem2020stereoset}.
\\

Coming to other two datasets namely CrowS-pairs \cite{nangia2020crows}, Social bias frames \cite{sap2019social}. CrowS-pairs focuses on explicit expression of stereotypes about historically disadvantaged groups in the United States. 9 types of biases are covered in the CrowSpair, namely race, gender/gender identity, sexual orientation, religion, age, nationality, disability, physical appearance, socioeconomic status or occupation. This list is narrowed version of US Equal Employment Opportunities Commission's list of protected categories\footnote{https://www.eeoc.gov/prohibited-employment-policiespractices} \cite{nangia2020crows}. CrowSpair follow the same style that of \cite{nadeem2020stereoset}, where two pairs of sentences, one of which demonstrate a stereotype and the second sentence can demonstrate a violation against a stereotype (anti-stereotype). Both the stereotype and anti-stereotype sentences focuses on demonstrating or violating disadvantaged group in United States. The two pairs of sentences (stereo and anti-stereo) differ by only the group word being spoken about. CrowSpair cover intrasentence samples.

The difference between stereoset and crowspair anti-stereotype and stereotype is that stereoset anti-stereotypes are based on attribute term while the crowSpair anti-stereotype is based on opposing historical group. 

\begin{itemize}
    \item Why three datasets?? CrowS-Pairs \cite{nangia2020crows}, Social bias frames \cite{sap2019social}, Stereo Set \cite{nadeem2020stereoset}
    \begin{enumerate}
        \item Crowdsourcing have advantages over template based sentences such as "This is [target]" and "they are [attribute]", As they follow natural context. Crowdsourced datasets could capture wider range of stereotypes with better ecological validity when compared to template based or any NLP researcher could come up with. \cite{blodgett2021stereotyping}
        \item All the three papers have been recently published (relative the period of starting thesis).
        \item Annotators have been asked to give realistic stereotype and anti-stereotype samples.
    \end{enumerate}
    \item The pitfalls regarding the data are discussed in the limitation section 
\end{itemize}
\section{Exploratory data analysis}\label{EDA}
\begin{itemize}
    \item Stereotypes are considered with respect to historically disadvantaged groups as well as others provided in the list, hence the stereotypic sentences include positive stereotypes as well as negative stereotypes.
    \item 
\end{itemize}
\section{Data preparation}\label{data preparation}
    \begin{itemize}
        \item Target label definitions used in dataset
        \item Combinations and eliminations done after combining three datasets
    \end{itemize}